{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se debe tener instalado en local Ollama y llama2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !pip install langchain pypdf openai chromadb tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in ./.venv/lib/python3.10/site-packages (from langchain-community) (0.2.3)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in ./.venv/lib/python3.10/site-packages (from langchain-community) (0.2.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.10/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.10/site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./.venv/lib/python3.10/site-packages (from langchain-community) (0.1.69)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.10/site-packages (from langchain-community) (8.3.0)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.10/site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.6 langchain-community-0.2.1 marshmallow-3.21.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargado paper1.pdf\n",
      "Descargado paper2.pdf\n",
      "Descargado paper3.pdf\n",
      "Descargado paper4.pdf\n",
      "Descargado paper5.pdf\n",
      "Contenido de ml_papers:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "urls = [\n",
    "    'https://arxiv.org/pdf/2306.06031v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.12156v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.14289v1.pdf',\n",
    "    'https://arxiv.org/pdf/2305.10973v1.pdf',\n",
    "    'https://arxiv.org/pdf/2306.13643v1.pdf'\n",
    "]\n",
    "\n",
    "ml_papers = []\n",
    "\n",
    "for i, url in enumerate(urls):\n",
    "    response = requests.get(url)\n",
    "    filename = f'paper{i+1}.pdf'\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "        print(f'Descargado {filename}')\n",
    "\n",
    "        loader = PyPDFLoader(filename)\n",
    "        data = loader.load()\n",
    "        ml_papers.extend(data)\n",
    "\n",
    "# Utiliza la lista ml_papers para acceder a los elementos de todos los documentos descargados\n",
    "print('Contenido de ml_papers:')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " 57,\n",
       " Document(page_content='Figure 1: FinGPT Framework.\\n4.1 Data Sources\\nThe first stage of the FinGPT pipeline involves the collec-\\ntion of extensive financial data from a wide array of online\\nsources. These include, but are not limited to:\\n•Financial news: Websites such as Reuters, CNBC, Yahoo\\nFinance, among others, are rich sources of financial news\\nand market updates. These sites provide valuable informa-\\ntion on market trends, company earnings, macroeconomic\\nindicators, and other financial events.\\n•Social media : Platforms such as Twitter, Facebook, Red-\\ndit, Weibo, and others, offer a wealth of information in\\nterms of public sentiment, trending topics, and immediate\\nreactions to financial news and events.\\n•Filings : Websites of financial regulatory authorities, such\\nas the SEC in the United States, offer access to company\\nfilings. These filings include annual reports, quarterly earn-\\nings, insider trading reports, and other important company-\\nspecific information. Official websites of stock exchanges\\n(NYSE, NASDAQ, Shanghai Stock Exchange, etc.) pro-\\nvide crucial data on stock prices, trading volumes, company\\nlistings, historical data, and other related information.\\n•Trends : Websites like Seeking Alpha, Google Trends, and\\nother finance-focused blogs and forums provide access to\\nanalysts’ opinions, market predictions, the movement of\\nspecific securities or market segments and investment ad-\\nvice.•Academic datasets : Research-based datasets that offer cu-\\nrated and verified information for sophisticated financial\\nanalysis.\\nTo harness the wealth of information from these diverse\\nsources, FinGPT incorporates data acquisition tools capable\\nof scraping structured and unstructured data, including APIs,\\nweb scraping tools, and direct database access where avail-\\nable. Moreover, the system is designed to respect the terms\\nof service of these platforms, ensuring data collection is ethi-\\ncal and legal.\\nData APIs : In the FinGPT framework, APIs are used not\\nonly for initial data collection but also for real-time data up-\\ndates, ensuring the model is trained on the most current data.\\nAdditionally, error handling and rate-limiting strategies are\\nimplemented to respect API usage limits and avoid disrup-\\ntions in the data flow.\\n4.2 Real-Time Data Engineering Pipeline for\\nFinancial NLP\\nFinancial markets operate in real-time and are highly sensi-\\ntive to news and sentiment. Prices of securities can change\\nrapidly in response to new information, and delays in pro-\\ncessing that information can result in missed opportunities or\\nincreased risk. As a result, real-time processing is essential in\\nfinancial NLP.\\nThe primary challenge with a real-time NLP pipeline is\\nmanaging and processing the continuous inflow of data ef-\\nficiently. The first step in the pipeline is to set up a system to', metadata={'source': 'paper1.pdf', 'page': 3}))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ml_papers), len(ml_papers), ml_papers[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,  #Tamaño del texto de cada chunk\n",
    "    chunk_overlap=200, #Hace que al principio de cada chunk esten 200 caracteres del anterior, para dar continuidad\n",
    "    length_function=len #Se hace que el chunk sea por longitud\n",
    "    # Hay una forma de evaluar los chunks https://chunkviz.up.railway.app/\n",
    "    )\n",
    "\n",
    "documents = text_splitter.split_documents(ml_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211,\n",
       " Document(page_content='highly volatile, changing rapidly in response to news events\\nor market movements.\\nTrends , often observable through websites like Seeking\\nAlpha, Google Trends, and other finance-oriented blogs and\\nforums, offer critical insights into market movements and in-\\nvestment strategies. They feature:\\n•Analyst perspectives: These platforms provide access to\\nmarket predictions and investment advice from seasoned\\nfinancial analysts and experts.\\n•Market sentiment: The discourse on these platforms can\\nreflect the collective sentiment about specific securities,\\nsectors, or the overall market, providing valuable insights\\ninto the prevailing market mood.\\n•Broad coverage: Trends data spans diverse securities and\\nmarket segments, offering comprehensive market coverage.\\nEach of these data sources provides unique insights into\\nthe financial world. By integrating these diverse data types,\\nfinancial language models like FinGPT can facilitate a com-\\nprehensive understanding of financial markets and enable ef-\\nfective financial decision-making.\\n3.2 Challenges in Handling Financial Data\\nWe summarize three major challenges for handling financial\\ndata as follows:\\n•High temporal sensitivity : Financial data are character-\\nized by their time-sensitive nature. Market-moving news or\\nupdates, once released, provide a narrow window of oppor-\\ntunity for investors to maximize their alpha (the measure of\\nan investment’s relative return).•High dynamism : The financial landscape is perpetually', metadata={'source': 'paper1.pdf', 'page': 2}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents), documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings e ingesta de datos vectorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "ollama = ChatOllama(model=\"llama2\")\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"llama2\")\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "# Un retriever convierte la base de datos \"retorna\" los fragmentos clave para responder la pregunta\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={\"k\": 3} # Solo busca los 3 fragmentos que más se parecen\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chat = ChatOllama(\n",
    "    model_name='llama2'\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    chain_type=\"stuff\",  # Lo que quepa en el prompt vamos a utilizar\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FInGPT is an open-source large language model for the financial sector. It is designed to provide researchers and practitioners with accessible and transparent resources to develop their own financial language models (FinLLMs). FinGPT takes a data-centric approach, unlike proprietary models that rely on privileged access to high-quality financial data.\\n\\nThe paper presents an overview of FinGPT and its importance in democratizing financial language models. The authors highlight the need for an automatic data curation pipeline and a lightweight low-rank adaptation technique in building FinGPT. They also showcase several potential applications of FinGPT, such as robo-advising, algorithmic trading, and low-code development.\\n\\nFinGPT is part of the open-source AI4Finance community, which aims to stimulate innovation, democratize financial language models, and unlock new opportunities in open finance. Two associated code repos are available on GitHub.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"qué es fingpt?\"  # Me apareció que ahora no se usa .run sino invoke\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, it seems that finetuning a model like FiGPT (a lightweight image encoder) can be challenging for several reasons:\\n\\n1. Data quality and availability: The performance of the model depends on the quality and quantity of the training data. However, high-quality financial data can be difficult to obtain, especially for non-mainstream assets like cryptocurrencies.\\n2. Customization: FiGPT champions open-source values, which means that users need to adapt the model to their specific needs. This can be time-consuming and require significant expertise in machine learning.\\n3. Cost: The cost of training a model like FiGPT can be high, typically between $100 to $300. This can be a barrier for individuals or organizations with limited budgets.\\n4. Computational resources: Training a large language model like FiGPT requires significant computational resources, which can be challenging for mobile devices or low-power hardware.\\n5. Mask decoder: The mask decoder in FiGPT is another component that needs to be fine-tuned, which adds an additional layer of complexity to the training process.\\n6. Distillation: Decoupled distillation, which involves training the model on a smaller dataset, can be less computationally expensive than coupled distillation, but it may not achieve the same level of performance as the latter.\\n\\nOverall, fine-tuning a model like FiGPT can be complex due to these factors, but there are ways to simplify the process, such as using pre-trained models or leveraging open-source libraries and tools.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"qué hace complicado entrenar un modelo como el fingpt?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, \"Fast Segment\" seems to refer to a task or technique related to image segmentation. However, I cannot provide a definitive answer without more information or context. Could you please provide more details or clarify what you mean by \"Fast Segment\"?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"qué es fast segment?\"\n",
    "qa_chain.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, I can answer your question as follows:\\n\\nFastSAM and MobileSAM are both variants of the Segment Anything Model (SAM), a vision foundation model that can be fine-tuned for various tasks. The main difference between FastSAM and MobileSAM is their design and purpose:\\n\\n1. FastSAM:\\nFastSAM uses TensorRT for inference, which allows for faster performance compared to traditional SAM. This is achieved by leveraging the optimized hardware of TensorRT, such as GPUs or TPUs, to accelerate the inference process. FastSAM is designed primarily for high-performance computing tasks that require fast inference times, such as real-time object detection or autonomous driving applications.\\n2. MobileSAM:\\nMobileSAM is designed for mobile and edge devices, where computational resources are limited. It uses a different architecture and training procedure than FastSAM to achieve better performance on these devices. MobileSAM trades off some of the accuracy of FastSAM in favor of lower computational requirements, making it more suitable for resource-constrained environments. Its main application is in mobile and edge AI scenarios, such as image or video processing on smartphones or IoT devices.\\n\\nIn summary, FastSAM is optimized for high-performance computing tasks, while MobileSAM is designed for mobile and edge devices with limited resources.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"cuál es la diferencia entre fast sam y mobile sam?\"\n",
    "qa_chain.run(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
